{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utah Home Value Predictor\n",
    "This is a regression ML project that inputs an image of a house in the Wasatch Front and outputs an estimated home value as of 2023.\n",
    "The training data is based on assessor-provided images of single-family homes in Davis County, UT.\n",
    "Test data should be valid for homes in non-rural regions of Weber, Davis, Salt Lake, and Utah County, UT, but there may be slight variations due to location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-ML imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "dtype = {\n",
    "  \"PARCEL ID\": str,\n",
    "  \"PARCEL ZIP CODE\": str\n",
    "}\n",
    "dtype_main = {\n",
    "  \"Parcel ID\": str,\n",
    "  \"Assessed Value\": np.float32\n",
    "}\n",
    "allowed_prop_types = ['Residential']  # allowed property types on the Davis County parcel system\n",
    "blacklist_parcels = [  # parcels with invalid images or too much foliage blocking the house\n",
    "  '010450014',\n",
    "  '012590319',\n",
    "  '030810075',\n",
    "  '050330045',\n",
    "  '050460021',\n",
    "  '050780007',\n",
    "  '050790009',\n",
    "  '051130041',\n",
    "  '060140083',\n",
    "  '060920057',\n",
    "  '070130004',\n",
    "  '070140068',\n",
    "  '073010128',\n",
    "  '080120020',\n",
    "  '080450003',\n",
    "  '080980011',\n",
    "  '081690013',\n",
    "  '082280005',\n",
    "  '084470305',\n",
    "  '085850315',\n",
    "  '090480038',\n",
    "  '090600006',\n",
    "  '091010078',\n",
    "  '093380401',\n",
    "  '100810002',\n",
    "  '111870221',\n",
    "  '114710015',\n",
    "  '114930076',\n",
    "  '116520007',\n",
    "  '117750010',\n",
    "  '127180016',\n",
    "  '130170032',\n",
    "  '130760106',\n",
    "  '131630030',\n",
    "  '140430050',\n",
    "  '140560003',\n",
    "  '140630013',\n",
    "  '140650050',\n",
    "  '140680016',\n",
    "  '143430059',\n",
    "  '143510048',\n",
    "  '144450025',\n",
    "  '145480125',\n",
    "  '150400102',\n",
    "]\n",
    "random_seed = '70f2f796-b097-4215-b2a8-aa54cd499bbf'  # you can change this but don't be surprised if you get invalid homes that you have to filter through; this seed has been checked up to 1300 parcels\n",
    "train_count = 1000  # how many instances to pull for the training/validation\n",
    "epochs = 20  # how many epochs\n",
    "debug = True  # some print statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 (optional): Download/Filter Parcel Master\n",
    "You can download the Parcel Master at https://opendata.gis.utah.gov. There is no direct URL for this so just save it as `./parcel_list/parcels_raw.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parcel_list/parcels_raw.csv', 'r') as f:\n",
    "  df = pd.read_csv(f, dtype=dtype)\n",
    "\n",
    "  # Remove duplicate parcel IDs\n",
    "  df = df.drop_duplicates(subset='PARCEL ID', keep=\"last\")\n",
    "\n",
    "  # Don't include any parcels that are not Private ownership\n",
    "  df = df[df['OWNERSHIP TYPE'] == 'Private']\n",
    "\n",
    "  # Don't include any parcels that have more than 10000 sqm (~2.5 acres) as that will mess up the data collection\n",
    "  df = df[df['Shape__Area'] < 10000]\n",
    "\n",
    "  # Only keep the Parcel IDs and ZIPs as a primary key\n",
    "  df = df[['PARCEL ID','PARCEL ZIP CODE','Shape__Area']]\n",
    "\n",
    "  df.to_csv('parcel_list/parcels_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Get Data from DC Parcel Search\n",
    "This will get the data + images from the Davis County Parcel Search. If you already have files in `images/` and `property_attributes.csv` the download script will not be invoked and only `main_df` needs be instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of filtered parcels\n",
    "with open('parcel_list/parcels_filtered.csv', 'r') as f:\n",
    "  df = pd.read_csv(f, dtype=dtype, index_col='PARCEL ID')\n",
    "\n",
    "# set seed for parcel randomization\n",
    "parcels = df.index.values.tolist()\n",
    "random.seed(random_seed)\n",
    "random.shuffle(parcels)\n",
    "\n",
    "try:\n",
    "  with open('property_attributes.csv', 'r') as f:\n",
    "    # if file already exists, automatically load it\n",
    "    main_df = pd.read_csv(f, dtype=dtype_main, index_col='Parcel ID')\n",
    "except:\n",
    "  # Main Data collection if missing\n",
    "  i = -1\n",
    "  i_success = 0\n",
    "  main_df = pd.DataFrame(columns=[\n",
    "    'Parcel ID',\n",
    "    'Property Type',\n",
    "    'Property Size',\n",
    "    'Year Built',\n",
    "    'Assessed Value'\n",
    "  ], dtype=dtype_main)\n",
    "  main_df = main_df.set_index('Parcel ID')\n",
    "\n",
    "  while i_success < train_count:\n",
    "    i += 1\n",
    "\n",
    "    if debug:\n",
    "      print(f'Trying iloc={i} ({parcels[i]})')\n",
    "\n",
    "    data_core = requests.get(f'https://webportal.daviscountyutah.gov/App/PropertySearch/api/parcel/buildings/{parcels[i]}').json()\n",
    "\n",
    "    # Blank parcel (no property)\n",
    "    if len(data_core) == 0:\n",
    "      if debug:\n",
    "        print(f'Skipped {parcels[i]} (REASON: data)')\n",
    "      continue\n",
    "\n",
    "    data_core = data_core[0]\n",
    "\n",
    "    # Missing physical information\n",
    "    if data_core[\"propertyType\"] not in allowed_prop_types or\\\n",
    "      'bltasYearBuilt' not in data_core or\\\n",
    "      'landGrossAcres' not in data_core or\\\n",
    "      data_core['landGrossAcres'] == 0:\n",
    "      if debug:\n",
    "        print(f'Skipped {parcels[i]} (REASON: data_core)')\n",
    "      continue\n",
    "    \n",
    "    data_value = requests.get(f'https://webportal.daviscountyutah.gov/App/PropertySearch/api/taxrecord/{parcels[i]}').json()\n",
    "\n",
    "    # Missing market value information\n",
    "    if len(data_value) == 0 or\\\n",
    "      'marketImproveValue' not in data_value[0] or\\\n",
    "      'marketLandValue' not in data_value[0] or\\\n",
    "      data_value[0]['marketImproveValue'] == 0 or\\\n",
    "      data_value[0]['marketLandValue'] == 0:\n",
    "      if debug:\n",
    "        print(f'Skipped {parcels[i]} (REASON: data_value)')\n",
    "      continue\n",
    "\n",
    "    data_image = requests.get(f'https://webportal.daviscountyutah.gov/App/PropertySearch/api/parcel/images/{parcels[i]}').json()\n",
    "\n",
    "    # Missing image\n",
    "    if len(data_image) == 0 or parcels[i] in blacklist_parcels:\n",
    "      if debug:\n",
    "        print(f'Skipped {parcels[i]} (REASON: data_image)')\n",
    "      continue\n",
    "    \n",
    "    main_df.loc[parcels[i]] = [\n",
    "      data_core[\"propertyType\"],\n",
    "      data_core[\"landGrossAcres\"],\n",
    "      data_core[\"bltasYearBuilt\"],\n",
    "      data_value[0]['marketImproveValue'] + data_value[0]['marketLandValue']\n",
    "    ]\n",
    "\n",
    "    # export image\n",
    "    raw_image = str.encode(data_image[0].replace('data:image/jpeg;base64,', ''))\n",
    "    \n",
    "    with open(f'images/{parcels[i]}.jpg', 'wb') as b:\n",
    "      b.write(base64.decodebytes(raw_image))\n",
    "    \n",
    "    i_success += 1\n",
    "    \n",
    "  main_df.to_csv('property_attributes.csv')\n",
    "main_df[\"Assessed Value\"] = main_df[\"Assessed Value\"] / 1000000\n",
    "main_df[\"Assessed Value\"] = main_df[\"Assessed Value\"].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize all images to be 640x480 ~ 4:3 ratio\n",
    "def convert_image(i):\n",
    "  with open(i, 'rb') as f:\n",
    "    img = Image.open(f)\n",
    "    w = img.width\n",
    "    h = img.height\n",
    "\n",
    "    if w == 640 and h == 480:\n",
    "      return\n",
    "    \n",
    "    # other aspect ratio in landscape mode\n",
    "    elif w >= h * 4/3:\n",
    "      target_w = h * 4/3\n",
    "      biaxial_cropped_w = (w - target_w) / 2\n",
    "\n",
    "      img = img.crop((biaxial_cropped_w, 0, w - biaxial_cropped_w, h))\n",
    "    \n",
    "    # other aspect ratio in portrait mode\n",
    "    else:\n",
    "      target_h = w / (4/3)\n",
    "      biaxial_cropped_h = (h - target_h) / 2\n",
    "\n",
    "      img = img.crop((0, biaxial_cropped_h, w, h - biaxial_cropped_h))\n",
    "    \n",
    "    img = img.resize((640, 480))\n",
    "    img.save(i)\n",
    "\n",
    "for i in os.listdir('images'):\n",
    "  if '.jpg' in i:  # valid image\n",
    "    convert_image(f\"images/{i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Time to Train!\n",
    "Let's train our data now using a simple convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ML imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# function to transform PIL image into np tensor\n",
    "transform_func = transforms.Compose([\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# order of priority: NVIDIA Cuda, Apple MPS, CPU.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "# Dataset class: automatically partitions into 80% train/20% validation\n",
    "class HomeValueDataset(Dataset):\n",
    "  def __init__(self, train=True):\n",
    "    self.imgs = [transform_func(Image.open(f\"images/{x}.jpg\")) for x in main_df.index.values]\n",
    "    self.index_modifier = 0 if train else train_count - (train_count // 5)\n",
    "    self.train = train\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    input = self.imgs[index+self.index_modifier]\n",
    "    output = main_df[\"Assessed Value\"].iloc[index+self.index_modifier]\n",
    "\n",
    "    return input, output\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs) - (len(self.imgs) // 5) if self.train else len(self.imgs) // 5\n",
    "\n",
    "class HomeValueCNN(nn.Module):\n",
    "  def __init__(self, num_outputs=1):\n",
    "    super(HomeValueCNN, self).__init__()\n",
    "\n",
    "    # Load ResNet-18 model\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Replace the fully connected layer to output num_outputs for regression\n",
    "    self.model = nn.Sequential(\n",
    "        resnet,\n",
    "        nn.Linear(resnet.fc.in_features, num_outputs)  # Modify output layer for regression\n",
    "    )\n",
    "    \n",
    "    # Remove the original fully connected layer from ResNet\n",
    "    self.model[0].fc = nn.Identity()\n",
    "        \n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = HomeValueCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.0792, Validation Loss: 0.1483\n",
      "Epoch 2/20, Train Loss: 0.0348, Validation Loss: 0.0572\n",
      "Epoch 3/20, Train Loss: 0.0219, Validation Loss: 0.0513\n",
      "Epoch 4/20, Train Loss: 0.0166, Validation Loss: 0.0311\n",
      "Epoch 5/20, Train Loss: 0.0124, Validation Loss: 0.0256\n",
      "Epoch 6/20, Train Loss: 0.0103, Validation Loss: 0.0305\n",
      "Epoch 7/20, Train Loss: 0.0098, Validation Loss: 0.0398\n",
      "Epoch 8/20, Train Loss: 0.0088, Validation Loss: 0.0278\n",
      "Epoch 9/20, Train Loss: 0.0094, Validation Loss: 0.0356\n",
      "Epoch 10/20, Train Loss: 0.0084, Validation Loss: 0.0382\n",
      "Epoch 11/20, Train Loss: 0.0101, Validation Loss: 0.0301\n",
      "Epoch 12/20, Train Loss: 0.0073, Validation Loss: 0.0297\n",
      "Epoch 13/20, Train Loss: 0.0084, Validation Loss: 0.0956\n",
      "Epoch 14/20, Train Loss: 0.0082, Validation Loss: 0.0339\n",
      "Epoch 15/20, Train Loss: 0.0092, Validation Loss: 0.0344\n",
      "Epoch 16/20, Train Loss: 0.0084, Validation Loss: 0.0380\n",
      "Epoch 17/20, Train Loss: 0.0106, Validation Loss: 0.0267\n",
      "Epoch 18/20, Train Loss: 0.0086, Validation Loss: 0.0335\n",
      "Epoch 19/20, Train Loss: 0.0048, Validation Loss: 0.0293\n",
      "Epoch 20/20, Train Loss: 0.0039, Validation Loss: 0.0317\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# main train loop\n",
    "def train_model(model, train_loader, val_loader, epochs=epochs):\n",
    "  model.to(device)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    training_run_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      \n",
    "      # Convert labels to float for regression and adjust shape\n",
    "      labels = labels.float().unsqueeze(1)  # Change shape from [batch_size] to [batch_size, 1]\n",
    "\n",
    "      # Zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # Backward pass and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      training_run_loss += loss.item() * images.size(0)\n",
    "\n",
    "    training_loss = training_run_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "      for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "      \n",
    "        # Convert labels to float for regression and adjust shape\n",
    "        labels = labels.float().unsqueeze(1)  # Change shape from [batch_size] to [batch_size, 1]\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {training_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "# Example usage (assuming train_loader and val_loader are defined DataLoader objects)\n",
    "train_dataset = HomeValueDataset(train=True)\n",
    "val_dataset = HomeValueDataset(train=False)\n",
    "\n",
    "# Initialize DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=5, shuffle=False, pin_memory=True)\n",
    "\n",
    "train_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'utsfhval.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: The Tenuous Test\n",
    "How did our model perform? We'll evaluate by using a simple mean squared error. Multiply the MSE by 1 million to get the average error in $$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current MSE: 0.2174291739463806\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for i in os.listdir(\"test\"):\n",
    "  if '.jpg' in i:\n",
    "    msrp = float(re.findall(r'\\d+', i)[0]) * 1000\n",
    "\n",
    "    convert_image(f\"test/{i}\")\n",
    "    test_image_tensor = transform_func(Image.open(f\"test/{i}\")).unsqueeze(0)\n",
    "    test_image_tensor = test_image_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      prediction = model(test_image_tensor)\n",
    "      test_data.append(\n",
    "        (msrp, prediction.item() * 1e6)\n",
    "      )\n",
    "\n",
    "print(f\"Current MSE: {sum([abs((x - y)/1e6) for x, y in test_data])/len(test_data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
